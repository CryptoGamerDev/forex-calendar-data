name: Update and Optimize Forex Calendar Data

on:
  schedule:
    - cron: '0 */2 * * *'  # Aktualizuj co 2 godziny
  workflow_dispatch:
    inputs:
      reason:
        description: 'Reason for manual run'
        required: false
        default: 'Manual trigger'

permissions:
  contents: write

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Download and Optimize Forex Data
        run: |
          echo "Downloading and optimizing data for MQL5..."
          python3 << 'EOF'
          import csv
          import requests
          from datetime import datetime
          import re

          # Pobierz dane
          url = "https://nfs.faireconomy.media/ff_calendar_thisweek.csv"
          response = requests.get(url)
          
          if response.status_code != 200:
              print("ERROR: Failed to download data")
              exit(1)

          # Przeczytaj dane
          csv_data = response.text.splitlines()
          reader = csv.reader(csv_data)
          rows = list(reader)

          if len(rows) <= 1:
              print("ERROR: No data received")
              exit(1)

          # Przygotuj zoptymalizowany plik
          optimized_rows = []
          seen_events = set()  # Do Å›ledzenia duplikatÃ³w
          
          # NagÅ‚Ã³wek z dodatkowymi polami dla MQL5
          optimized_rows.append([
              'Title', 'Country', 'Date', 'Time', 'Time24h', 'Impact', 
              'Forecast', 'Previous', 'HasForecast', 'HasPrevious', 'Importance'
          ])

          # Mapowanie Impact na wartoÅ›ci numeryczne dla MQL5
          impact_to_importance = {
              'High': 3,
              'Medium': 2, 
              'Low': 1,
              'Holiday': 0
          }

          def convert_time_to_24h(time_str):
              """Konwertuj czas AM/PM na format 24-godzinny"""
              if not time_str or time_str == '':
                  return ''
              
              # UsuÅ„ spacje i zamieÅ„ na maÅ‚e litery
              time_str = time_str.lower().replace(' ', '')
              
              # Rozdziel czas i AM/PM
              match = re.match(r'(\d+):?(\d+)?(am|pm)', time_str)
              if not match:
                  return time_str
                  
              hour = int(match.group(1))
              minute = match.group(2) if match.group(2) else '00'
              period = match.group(3)
              
              # Konwersja na 24h
              if period == 'pm' and hour != 12:
                  hour += 12
              elif period == 'am' and hour == 12:
                  hour = 0
                  
              return f"{hour:02d}:{minute}"

          def is_duplicate_event(row):
              """SprawdÅº czy wydarzenie jest duplikatem"""
              key = (row[0], row[1], row[2], row[3])  # Title, Country, Date, Time
              if key in seen_events:
                  return True
              seen_events.add(key)
              return False

          # PrzetwÃ³rz wiersze danych
          for row in rows[1:]:  # Pomijaj nagÅ‚Ã³wek
              if len(row) < 8:
                  continue
                  
              # SprawdÅº duplikaty
              if is_duplicate_event(row):
                  continue
                  
              title, country, date, time, impact, forecast, previous = row[:7]
              
              # Konwertuj czas na format 24h
              time24h = convert_time_to_24h(time)
              
              # Ustaw domyÅ›lne wartoÅ›ci dla pustych pÃ³l
              forecast = forecast if forecast else 'N/A'
              previous = previous if previous else 'N/A'
              
              # Flagi czy ma forecast/previous
              has_forecast = '1' if forecast and forecast != 'N/A' else '0'
              has_previous = '1' if previous and previous != 'N/A' else '0'
              
              # WartoÅ›Ä‡ numeryczna dla impact
              importance = str(impact_to_importance.get(impact, 0))
              
              optimized_rows.append([
                  title, country, date, time, time24h, impact,
                  forecast, previous, has_forecast, has_previous, importance
              ])

          # Zapisz zoptymalizowany plik
          with open('forex_data_optimized.csv', 'w', newline='', encoding='utf-8') as f:
              writer = csv.writer(f)
              writer.writerows(optimized_rows)

          print(f"SUCCESS: Optimized {len(optimized_rows)-1} events for MQL5")
          
          # Statystyki
          high_impact = sum(1 for row in optimized_rows if row[5] == 'High')
          medium_impact = sum(1 for row in optimized_rows if row[5] == 'Medium')
          with_forecast = sum(1 for row in optimized_rows[1:] if row[8] == '1')
          
          print(f"Statistics: High impact: {high_impact}, Medium: {medium_impact}, With forecast: {with_forecast}")
          EOF

      - name: Create simplified version for EA
        run: |
          echo "Creating simplified CSV for EA..."
          python3 << 'EOF'
          import csv

          # StwÃ³rz uproszczonÄ… wersjÄ™ tylko z najwaÅ¼niejszymi kolumnami
          with open('forex_data_optimized.csv', 'r', encoding='utf-8') as f:
              reader = csv.reader(f)
              rows = list(reader)

          # Uproszczony plik - tylko kolumny potrzebne do szybkiego parsowania w MQL5
          simplified_rows = []
          simplified_rows.append(['Title', 'Country', 'Date', 'Time24h', 'Importance', 'Forecast', 'Previous'])

          for row in rows[1:]:
              simplified_rows.append([
                  row[0],  # Title
                  row[1],  # Country
                  row[2],  # Date
                  row[4],  # Time24h
                  row[10], # Importance (numeryczna)
                  row[6],  # Forecast
                  row[7]   # Previous
              ])

          with open('forex_data_simple.csv', 'w', newline='', encoding='utf-8') as f:
              writer = csv.writer(f)
              writer.writerows(simplified_rows)

          print(f"Created simplified version with {len(simplified_rows)-1} events")
          EOF

      - name: Verify and display results
        run: |
          echo "=== OPTIMIZED CSV (for analysis) ==="
          wc -l forex_data_optimized.csv
          echo "First 3 lines:"
          head -3 forex_data_optimized.csv
          
          echo ""
          echo "=== SIMPLE CSV (for MQL5 EA) ==="
          wc -l forex_data_simple.csv
          echo "First 5 lines:"
          head -5 forex_data_simple.csv
          
          echo ""
          echo "=== STATISTICS ==="
          python3 << 'EOF'
          import csv
          with open('forex_data_simple.csv', 'r', encoding='utf-8') as f:
              reader = csv.reader(f)
              rows = list(reader)
              
          total = len(rows) - 1
          high_impact = sum(1 for row in rows[1:] if row[4] == '3')
          with_data = sum(1 for row in rows[1:] if row[5] != 'N/A' and row[6] != 'N/A')
          
          print(f"Total events: {total}")
          print(f"High importance (3): {high_impact}")
          print(f"Events with forecast data: {with_data}")
          EOF

      - name: Commit and push changes
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          git add forex_data_optimized.csv forex_data_simple.csv
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "ðŸ¤– Optimized forex data for MQL5 [$(date +%Y-%m-%d)]"
            git push
            echo "âœ… Optimized data committed"
          fi
