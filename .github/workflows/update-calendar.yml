name: Update and Optimize Forex Calendar Data

on:
  schedule:
    - cron: '0 */2 * * *'  # Aktualizuj co 2 godziny
  workflow_dispatch:
    inputs:
      reason:
        description: 'Reason for manual run'
        required: false
        default: 'Manual trigger'

permissions:
  contents: write

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Download raw data using curl (proven method)
        run: |
          echo "Downloading raw data using reliable curl method..."
          # U≈ºywamy sprawdzonej metody z curl kt√≥ra dzia≈Ça≈Ça
          curl -s -L "https://nfs.faireconomy.media/ff_calendar_thisweek.csv" -o forex_data_raw.csv
          
          # Sprawd≈∫ czy plik zosta≈Ç pobrany poprawnie
          if [ ! -s forex_data_raw.csv ]; then
            echo "ERROR: Failed to download data or file is empty"
            exit 1
          fi
          
          echo "‚úÖ Successfully downloaded raw data. Lines: $(wc -l < forex_data_raw.csv)"

      - name: Optimize data with Python
        run: |
          echo "Optimizing data for MQL5..."
          python3 << 'EOF'
          import csv
          import re

          # Wczytaj surowe dane pobrane przez curl
          try:
              with open('forex_data_raw.csv', 'r', encoding='utf-8') as f:
                  reader = csv.reader(f)
                  rows = list(reader)
          except Exception as e:
              print(f"ERROR: Failed to read raw data: {e}")
              exit(1)

          if len(rows) <= 1:
              print("ERROR: No data in raw file")
              exit(1)

          print(f"Processing {len(rows)-1} raw events...")

          # Przygotuj zoptymalizowany plik
          optimized_rows = []
          seen_events = set()
          
          # Nag≈Ç√≥wek dla zoptymalizowanego pliku
          optimized_rows.append([
              'Title', 'Country', 'Date', 'Time', 'Time24h', 'Impact', 
              'Forecast', 'Previous', 'HasForecast', 'HasPrevious', 'Importance'
          ])

          # Mapowanie Impact na warto≈õci numeryczne
          impact_to_importance = {
              'High': 3,
              'Medium': 2, 
              'Low': 1,
              'Holiday': 0
          }

          def convert_time_to_24h(time_str):
              """Konwertuj czas AM/PM na format 24-godzinny"""
              if not time_str or time_str.strip() == '':
                  return ''
              
              time_str = time_str.lower().strip()
              
              # Rozdziel czas i AM/PM
              match = re.match(r'(\d+):?(\d+)?\s*(am|pm)', time_str)
              if not match:
                  return time_str  # Zwr√≥ƒá orygina≈Ç je≈õli nie pasuje do formatu
                  
              hour = int(match.group(1))
              minute = match.group(2) if match.group(2) else '00'
              period = match.group(3)
              
              # Konwersja na 24h
              if period == 'pm' and hour != 12:
                  hour += 12
              elif period == 'am' and hour == 12:
                  hour = 0
                  
              return f"{hour:02d}:{minute}"

          # Przetw√≥rz wiersze danych
          processed_count = 0
          for row in rows[1:]:  # Pomijaj nag≈Ç√≥wek
              if len(row) < 8:
                  continue
                  
              title, country, date, time, impact, forecast, previous = row[:7]
              
              # Sprawd≈∫ duplikaty - u≈ºywajmy klucza z datƒÖ i czasem
              event_key = f"{title}_{country}_{date}_{time}"
              if event_key in seen_events:
                  continue
              seen_events.add(event_key)
              
              # Konwertuj czas na format 24h
              time24h = convert_time_to_24h(time)
              
              # Ustaw domy≈õlne warto≈õci dla pustych p√≥l
              forecast = forecast if forecast and forecast.strip() != '' else 'N/A'
              previous = previous if previous and previous.strip() != '' else 'N/A'
              
              # Flagi czy ma forecast/previous
              has_forecast = '1' if forecast != 'N/A' else '0'
              has_previous = '1' if previous != 'N/A' else '0'
              
              # Warto≈õƒá numeryczna dla impact
              importance = str(impact_to_importance.get(impact, 0))
              
              optimized_rows.append([
                  title, country, date, time, time24h, impact,
                  forecast, previous, has_forecast, has_previous, importance
              ])
              processed_count += 1

          # Zapisz zoptymalizowany plik
          try:
              with open('forex_data_optimized.csv', 'w', newline='', encoding='utf-8') as f:
                  writer = csv.writer(f)
                  writer.writerows(optimized_rows)
          except Exception as e:
              print(f"ERROR: Failed to write optimized file: {e}")
              exit(1)

          print(f"‚úÖ SUCCESS: Optimized {processed_count} events for MQL5")
          
          # Statystyki
          high_impact = sum(1 for row in optimized_rows[1:] if row[5] == 'High')
          medium_impact = sum(1 for row in optimized_rows[1:] if row[5] == 'Medium')
          with_forecast = sum(1 for row in optimized_rows[1:] if row[8] == '1')
          
          print(f"üìä Statistics: High impact: {high_impact}, Medium: {medium_impact}, With forecast: {with_forecast}")
          EOF

      - name: Create simplified version for EA
        run: |
          echo "Creating simplified CSV for EA..."
          python3 << 'EOF'
          import csv

          # Stw√≥rz uproszczonƒÖ wersjƒô tylko z najwa≈ºniejszymi kolumnami
          try:
              with open('forex_data_optimized.csv', 'r', encoding='utf-8') as f:
                  reader = csv.reader(f)
                  rows = list(reader)

              # Uproszczony plik - tylko kolumny potrzebne do szybkiego parsowania w MQL5
              simplified_rows = []
              simplified_rows.append(['Title', 'Country', 'Date', 'Time24h', 'Importance', 'Forecast', 'Previous'])

              for row in rows[1:]:
                  if len(row) >= 11:
                      simplified_rows.append([
                          row[0],  # Title
                          row[1],  # Country
                          row[2],  # Date
                          row[4],  # Time24h
                          row[10], # Importance (numeryczna)
                          row[6],  # Forecast
                          row[7]   # Previous
                      ])

              with open('forex_data_simple.csv', 'w', newline='', encoding='utf-8') as f:
                  writer = csv.writer(f)
                  writer.writerows(simplified_rows)

              print(f"‚úÖ Created simplified version with {len(simplified_rows)-1} events")
          except Exception as e:
              print(f"‚ùå Error creating simplified version: {e}")
              exit(1)
          EOF

      - name: Verify and display results
        run: |
          echo "=== VERIFICATION ==="
          echo "üìÅ Raw data lines: $(wc -l < forex_data_raw.csv)"
          echo "üîÑ Optimized data lines: $(wc -l < forex_data_optimized.csv)" 
          echo "‚ö° Simple data lines: $(wc -l < forex_data_simple.csv)"
          
          echo ""
          echo "=== SAMPLE OF SIMPLE CSV (for EA) ==="
          head -3 forex_data_simple.csv

      - name: Commit and push changes
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          git add forex_data_optimized.csv forex_data_simple.csv forex_data_raw.csv
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "ü§ñ Auto-update: Optimized forex data for MQL5 [$(date +%Y-%m-%d)]"
            git push
            echo "‚úÖ Changes committed successfully"
          fi
